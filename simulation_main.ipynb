{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd9d66c-0ded-407e-8355-bdf293a22156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "from simulation import *\n",
    "from model_function import *\n",
    "from evaluation_utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936a639c-fe79-41a0-acac-06c8b7132722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim(res):\n",
    "    expression = res[1]\n",
    "    partition = res[2]\n",
    "    partition[np.where(partition > 1)] = 0\n",
    "    feature_meta = res[3]\n",
    "    feature_meta_true = res[4]\n",
    "    true_meta = res[5]\n",
    "\n",
    "    # split into training and testing\n",
    "    target = expression[:, expression.shape[1]-1]\n",
    "    data = expression[:,0:(expression.shape[1]-1)]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "            data,target,test_size = 0.3,random_state = 0)\n",
    "\n",
    "    sparsify_coefficient = 0.3\n",
    "    threshold_layer_size = 100\n",
    "\n",
    "    # set the framework of the predicting net\n",
    "    num_hidden_layer_neuron_list = [20] \n",
    "\n",
    "    features_num = expression.shape[0]\n",
    "\n",
    "    sparsify_hidden_layer_size_dict = getLayerSizeList(partition, threshold_layer_size, sparsify_coefficient)\n",
    "    degree_dict = getNodeDegreeDict(partition)\n",
    "    partition_mtx_dict = getPartitionMatricesList(sparsify_hidden_layer_size_dict, degree_dict, feature_meta, partition)\n",
    "\n",
    "    keep_prob = 0.3\n",
    "\n",
    "    import warnings\n",
    "    import csv\n",
    "    count = 0\n",
    "    while (count<10):\n",
    "        net = Net(partition_mtx_dict, num_hidden_layer_neuron_list, keep_prob).to(\"cuda\")\n",
    "\n",
    "        BATCH_SIZE = 8\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "        torch.manual_seed=68\n",
    "\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)  #\n",
    "\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        x = (torch.from_numpy(x_train)).type(torch.FloatTensor)\n",
    "        y = (torch.from_numpy(y_train)).type(torch.LongTensor)\n",
    "\n",
    "        torch_dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "        loader = Data.DataLoader(\n",
    "            dataset=torch_dataset,    \n",
    "            batch_size=BATCH_SIZE,    \n",
    "            shuffle=True,             \n",
    "            num_workers=0           \n",
    "        )\n",
    "\n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "\n",
    "        acc_train = []\n",
    "        acc_test = []\n",
    "\n",
    "        for epoch in range(100): \n",
    "            net.train()\n",
    "            if epoch%10 == 0:\n",
    "                optimizer.param_groups[0]['lr'] *= 0.95\n",
    "\n",
    "            for step, (x_batch, y_batch) in enumerate(loader):\n",
    "                x_batch = x_batch.to('cuda')\n",
    "                y_batch = y_batch.to('cuda')\n",
    "                optimizer.zero_grad()\n",
    "                prediction = net(x_batch).to('cuda')\n",
    "                loss = loss_func(prediction,y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x = x.to('cuda')\n",
    "                y = y.to('cuda')\n",
    "                prediction = net(x).to('cuda')\n",
    "                pred_y = prediction.cpu().data.numpy().squeeze()\n",
    "                target_y = y.cpu().data.numpy()\n",
    "                accuracy = sum(target_y ==np.argmax(pred_y, axis=1))/len(target_y) \n",
    "                acc_train.append(accuracy)\n",
    "\n",
    "                test_input_tensor = (torch.from_numpy(x_test)).type(torch.FloatTensor).to('cuda')\n",
    "                out_probs = net(test_input_tensor).cpu().data.numpy().squeeze()\n",
    "                out_classes = np.argmax(out_probs, axis=1)\n",
    "                acc_test.append(sum(out_classes == y_test) / len(y_test))\n",
    "        \n",
    "\n",
    "        if np.mean(acc_train[-10:-1])>0.6:\n",
    "            count += 1\n",
    "            train_mean = np.mean(acc_train[-10:-1])\n",
    "            test_mean = np.mean(acc_test[-10:-1])\n",
    "\n",
    "            degree = np.sum((partition>0),0)+1\n",
    "            count_feature = (np.sum(feature_meta, 0)+1)\n",
    "\n",
    "            res = evalution(net, feature_meta_true, true_meta, degree, count_feature)\n",
    "\n",
    "            with open(\"sim_result.csv\",\"a\") as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow([n_feature, n_meta, N, multi_rate, poisson_rate, effective_ratio] + [train_mean, test_mean] + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8b1e56-e304-496e-b703-2e8b4d133255",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sim_result.csv\",\"a\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"n_feature\", \"n_meta\", \"N\", \"multi_rate\", \"poisson_rate\", \"effective_ratio\"] + [\"train_acc\", \"test_acc\", \"rate\", \"feature_auc\", \"feature_prauc\", \"meta_auc\", \"meta_prauc\", \"degree_auc\", 'degree_prauc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598040bc-e7d0-4369-b916-bb2e643fd3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish generating Y with 1 class 50, 0 class 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leqi/leqi/code/sparse_nn/pytorch_func2.py:167: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  self.linear.weight.data[self.mask] = 0 # zero out bad weights\n",
      "/home/leqi/leqi/code/sparse_nn/simulation_2.py:120: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  X = np.random.multivariate_normal(mean, covariance, N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish generating Y with 1 class 250, 0 class 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leqi/leqi/code/sparse_nn/simulation_2.py:120: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  X = np.random.multivariate_normal(mean, covariance, N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish generating Y with 1 class 500, 0 class 500\n"
     ]
    }
   ],
   "source": [
    "n_meta = 2000; n_feature = 1000; max_meta_link = 3; max_feature_link = 3; N = 500; link = 'logistic'; ba_m = 2; \n",
    "ba_power = 0.5; cov_base = 0.6\n",
    "\n",
    "for n_meta in [2000,1000]: #[1000, 1500, 2000]\n",
    "    for multi_rate in [0.5]:\n",
    "        for poisson_rate in [3,2,1]: #[1, 2, 3]\n",
    "            for effective_ratio in [0.05, 0.1]: #[0.05, 0.1]\n",
    "                for N in [100, 500, 1000, 2000, 4000]: ##500, 1000, 2000, 5000\n",
    "                    res = matching_simulation(n_feature, n_meta, N, ba_m, ba_power, multi_rate, poisson_rate, max_meta_link, max_feature_link, effective_ratio, link, cov_base)\n",
    "                    run_sim(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2147b3e6fdd6921cff5e8010b3c9f4db0817129c58e7659ca870f6deb419634"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
